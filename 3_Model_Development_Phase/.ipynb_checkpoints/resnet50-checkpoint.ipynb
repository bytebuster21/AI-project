{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/bytebuster21/AI-project/blob/main/resnet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Qser8Pe6RhPI",
    "outputId": "864588fa-17c3-4d16-8e5f-4679f96bcf90"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 16\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image \u001b[38;5;66;03m# For dummy image creation\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# --- 1. Mount Google Drive (Not strictly required for dummy data, but kept for context) ---\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# If you plan to save models/logs to Drive, or later switch to real data on Drive, run this.\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m     17\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGoogle Drive mounted successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50 # Import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image # For dummy image creation\n",
    "\n",
    "# --- 1. Mount Google Drive (Not strictly required for dummy data, but kept for context) ---\n",
    "# If you plan to save models/logs to Drive, or later switch to real data on Drive, run this.\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# print(\"Google Drive mounted successfully!\")\n",
    "\n",
    "# --- 2. Define dataset paths (using paths for dummy data) ---\n",
    "# These paths will be used for the dummy dataset created below.\n",
    "trainpath = '/content/resnet_train' # Using different paths to avoid conflicts with VGG16 dummy data\n",
    "testpath = '/content/resnet_test'\n",
    "\n",
    "print(f\"Using dummy dataset located at: \\n  Train: {trainpath}\\n  Test: {testpath}\")\n",
    "\n",
    "# --- 3. Create Dummy Data for Demonstration ---\n",
    "# This block creates placeholder images and directories, so the code runs out-of-the-box.\n",
    "# This ensures a consistent environment for demonstration.\n",
    "if os.path.exists(trainpath): # Clean up previous dummy data if it exists\n",
    "    shutil.rmtree(trainpath)\n",
    "if os.path.exists(testpath):\n",
    "    shutil.rmtree(testpath)\n",
    "\n",
    "print(\"Creating dummy dataset for demonstration...\")\n",
    "os.makedirs(os.path.join(trainpath, 'class_X'), exist_ok=True)\n",
    "os.makedirs(os.path.join(trainpath, 'class_Y'), exist_ok=True)\n",
    "os.makedirs(os.path.join(trainpath, 'class_Z'), exist_ok=True)\n",
    "\n",
    "os.makedirs(os.path.join(testpath, 'class_X'), exist_ok=True)\n",
    "os.makedirs(os.path.join(testpath, 'class_Y'), exist_ok=True)\n",
    "os.makedirs(os.path.join(testpath, 'class_Z'), exist_ok=True)\n",
    "\n",
    "def create_dummy_image(path, color, size=(299, 299)):\n",
    "    img = Image.new('RGB', size, color=color)\n",
    "    img.save(path)\n",
    "\n",
    "# Create dummy training images (simulate approx. 348 total images)\n",
    "for i in range(116): # 116 * 3 classes = 348\n",
    "    create_dummy_image(os.path.join(trainpath, 'class_X', f'imgX_{i:03d}.png'), (255, 150, 150))\n",
    "    create_dummy_image(os.path.join(trainpath, 'class_Y', f'imgY_{i:03d}.png'), (150, 255, 150))\n",
    "    create_dummy_image(os.path.join(trainpath, 'class_Z', f'imgZ_{i:03d}.png'), (150, 150, 255))\n",
    "\n",
    "# Create dummy testing images (simulate approx. 153 total images)\n",
    "for i in range(51): # 51 * 3 classes = 153\n",
    "    create_dummy_image(os.path.join(testpath, 'class_X', f'testX_{i:03d}.png'), (200, 100, 100))\n",
    "    create_dummy_image(os.path.join(testpath, 'class_Y', f'testY_{i:03d}.png'), (100, 200, 100))\n",
    "    create_dummy_image(os.path.join(testpath, 'class_Z', f'testZ_{i:03d}.png'), (100, 100, 200))\n",
    "\n",
    "print(f\"Dummy dataset created at {trainpath} and {testpath}\")\n",
    "\n",
    "\n",
    "# --- 4. Configure ImageDataGenerator instances ---\n",
    "# ResNet50 typically works well with 224x224, but 299x299 is also acceptable and consistent with prior discussion.\n",
    "TARGET_SIZE = (299, 299)\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "# Training Data Generator (with augmentation)\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,          # Normalize pixel values to [0, 1]\n",
    "    rotation_range=20,       # Randomly rotate images by up to 20 degrees\n",
    "    width_shift_range=0.1,   # Randomly shift images horizontally by up to 10%\n",
    "    height_shift_range=0.1,  # Randomly shift images vertically by up to 10%\n",
    "    shear_range=0.2,         # Apply shearing transformations\n",
    "    zoom_range=0.2,          # Randomly zoom in on images\n",
    "    horizontal_flip=True,    # Randomly flip images horizontally\n",
    "    fill_mode='nearest'      # Strategy for filling newly created pixels\n",
    ")\n",
    "\n",
    "# Test Data Generator (ONLY rescaling, no augmentation)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# --- 5. Flow Images from Directories ---\n",
    "print(\"\\nLoading images using ImageDataGenerator...\")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    trainpath,\n",
    "    target_size=TARGET_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical' # For multi-class classification (one-hot encoded labels)\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    testpath,\n",
    "    target_size=TARGET_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False # Essential for consistent evaluation results on test set\n",
    ")\n",
    "\n",
    "# Get number of classes and class names from the generator\n",
    "num_classes = train_generator.num_classes\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "\n",
    "print(f\"Found {train_generator.samples} training images belonging to {num_classes} classes.\")\n",
    "print(f\"Found {test_generator.samples} test images belonging to {num_classes} classes.\")\n",
    "print(\"Class Names:\", class_names)\n",
    "\n",
    "\n",
    "# --- 6. Build the Model (ResNet50 Feature Extractor + Custom Dense Layers) ---\n",
    "\n",
    "# Load the ResNet50 model pre-trained on ImageNet.\n",
    "# `include_top=False` means we are excluding the original classification head\n",
    "# as we will add our own custom layers for our specific dataset.\n",
    "base_model = ResNet50(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(TARGET_SIZE[0], TARGET_SIZE[1], 3) # Input shape for our images (299, 299, 3)\n",
    ")\n",
    "\n",
    "# Freeze the layers of the base model.\n",
    "# This makes them non-trainable, preserving the learned ImageNet features.\n",
    "# Only the newly added custom layers will be trained.\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create a Sequential model and add the ResNet50 base followed by custom classification layers.\n",
    "model = Sequential([\n",
    "    base_model, # The frozen ResNet50 convolutional base\n",
    "    Flatten(),  # Flattens the 3D output of the base model into a 1D vector\n",
    "    Dense(256, activation='relu'), # First fully connected layer\n",
    "    Dropout(0.5), # Dropout for regularization\n",
    "    Dense(128, activation='relu'), # Second fully connected layer\n",
    "    Dropout(0.4), # Another dropout layer\n",
    "    Dense(num_classes, activation='softmax') # Output layer: one neuron per class, softmax for probabilities\n",
    "])\n",
    "\n",
    "\n",
    "# --- 7. Configure the Learning Process (model.compile()) ---\n",
    "\n",
    "# Optimizer: Adam is a good general-purpose optimizer. Using a small learning rate.\n",
    "chosen_optimizer = Adam(learning_rate=0.0001)\n",
    "\n",
    "# Loss Function: 'categorical_crossentropy' for multi-class classification with one-hot encoded labels.\n",
    "chosen_loss_function = 'categorical_crossentropy'\n",
    "\n",
    "# Metrics: What to monitor during training (e.g., accuracy).\n",
    "chosen_metrics = ['accuracy']\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=chosen_optimizer,\n",
    "    loss=chosen_loss_function,\n",
    "    metrics=chosen_metrics\n",
    ")\n",
    "\n",
    "# Print the summary of the complete model architecture\n",
    "print(\"\\n--- Complete Model Summary (ResNet50 with Custom Dense Layers) ---\")\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# --- 8. Define Callbacks for Training Management ---\n",
    "# Callbacks are special functions called at various stages of the training process.\n",
    "\n",
    "# Directory to save model checkpoints\n",
    "checkpoint_dir = 'resnet_model_checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "checkpoint_filepath = os.path.join(checkpoint_dir, 'best_model_resnet50.h5')\n",
    "\n",
    "# 8.1 ModelCheckpoint: Save the best model encountered so far.\n",
    "# Saves if the 'val_loss' (validation loss) is the least.\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_loss',     # Monitor validation loss\n",
    "    save_best_only=True,    # Only save if val_loss improves\n",
    "    mode='min',             # 'min' mode for loss (we want the minimum loss)\n",
    "    verbose=1               # Show messages when saving\n",
    ")\n",
    "\n",
    "# 8.2 EarlyStopping: Stop training if validation loss doesn't improve for 'patience' epochs.\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,             # Stop if no improvement for 5 epochs\n",
    "    restore_best_weights=True, # Load weights from the best epoch before stopping\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 8.3 ReduceLROnPlateau: Reduce learning rate if validation loss plateaus.\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,             # Reduce LR by factor of 0.2\n",
    "    patience=3,             # Wait 3 epochs before reducing\n",
    "    min_lr=0.000001,        # Minimum learning rate\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 8.4 CSVLogger: Log training history to a CSV file.\n",
    "csv_logger = CSVLogger('resnet_training_log.csv', append=True)\n",
    "\n",
    "# List of all callbacks to be used during training\n",
    "callbacks_list = [\n",
    "    model_checkpoint,\n",
    "    early_stopping,\n",
    "    reduce_lr,\n",
    "    csv_logger\n",
    "]\n",
    "\n",
    "\n",
    "# --- 9. Train the Model (model.fit()) ---\n",
    "# This starts the training loop with your specified parameters and callbacks.\n",
    "print(\"\\n--- Starting Model Training ---\")\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE, # Number of batches per epoch\n",
    "    epochs=25, # Train for a maximum of 25 epochs\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples // BATCH_SIZE, # Number of validation batches per epoch\n",
    "    callbacks=callbacks_list, # Apply all defined callbacks\n",
    "    verbose=1 # Show training progress\n",
    ")\n",
    "\n",
    "print(\"\\nModel training complete.\")\n",
    "print(f\"Best model (based on validation loss) saved to: {checkpoint_filepath}\")\n",
    "\n",
    "\n",
    "# --- 10. Evaluate the Model ---\n",
    "# After training, load the best saved model and evaluate its performance on the test set.\n",
    "try:\n",
    "    loaded_model = tf.keras.models.load_model(checkpoint_filepath)\n",
    "    print(f\"\\nLoaded best model from {checkpoint_filepath}\")\n",
    "    loss, accuracy = loaded_model.evaluate(test_generator, steps=test_generator.samples // BATCH_SIZE)\n",
    "    print(f\"\\nFinal Test Loss (best model): {loss:.4f}, Final Test Accuracy (best model): {accuracy:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nCould not load best model for final evaluation: {e}\")\n",
    "    print(\"Evaluating the current model state (if training was not run or save failed).\")\n",
    "    loss, accuracy = model.evaluate(test_generator, steps=test_generator.samples // BATCH_SIZE)\n",
    "    print(f\"\\nFinal Test Loss: {loss:.4f}, Final Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "# --- 11. Plotting Training History ---\n",
    "# Visualize the training and validation accuracy/loss over epochs.\n",
    "if 'history' in locals() and history is not None:\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Plot training & validation accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy over Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot training & validation loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss over Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- 12. Clean up dummy data and checkpoints (Optional) ---\n",
    "# Uncomment these lines if you want to remove the dummy dataset and saved models after inspection.\n",
    "if os.path.exists(trainpath):\n",
    "    shutil.rmtree(trainpath)\n",
    "if os.path.exists(testpath):\n",
    "    shutil.rmtree(testpath)\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    shutil.rmtree(checkpoint_dir)\n",
    "if os.path.exists('resnet_training_log.csv'):\n",
    "    os.remove('resnet_training_log.csv')\n",
    "print(f\"\\nDummy dataset, checkpoints directory and training log file removed.\")\n",
    "model.save(\"resnet50_synapsescan.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPachJFitJT7sdNKIHU6aLC",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
