{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPh49bB3pXdvR+DdPGsBTA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bytebuster21/AI-project/blob/main/Train_the_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.optimizers import Adam # Explicitly import Adam optimizer\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger # Import useful callbacks\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# --- 1. Mount Google Drive (Not strictly required for dummy data, but kept for context) ---\n",
        "# If you plan to save models/logs to Drive, or later switch to real data on Drive, run this.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"Google Drive mounted successfully!\")\n",
        "\n",
        "# --- 2. Define dataset paths (using paths for dummy data) ---\n",
        "# These paths will be used for the dummy dataset created below.\n",
        "trainpath = '/content/train'\n",
        "testpath = '/content/test'\n",
        "\n",
        "print(f\"Using dummy dataset located at: \\n  Train: {trainpath}\\n  Test: {testpath}\")\n",
        "\n",
        "# --- 3. Create Dummy Data for Demonstration ---\n",
        "# This block creates placeholder images and directories, so the code runs out-of-the-box.\n",
        "# This ensures a consistent environment for demonstration.\n",
        "if os.path.exists(trainpath): # Clean up previous dummy data if it exists\n",
        "    shutil.rmtree(trainpath)\n",
        "if os.path.exists(testpath):\n",
        "    shutil.rmtree(testpath)\n",
        "\n",
        "print(\"Creating dummy dataset for demonstration...\")\n",
        "os.makedirs(os.path.join(trainpath, 'class_A'), exist_ok=True)\n",
        "os.makedirs(os.path.join(trainpath, 'class_B'), exist_ok=True)\n",
        "os.makedirs(os.path.join(trainpath, 'class_C'), exist_ok=True)\n",
        "\n",
        "os.makedirs(os.path.join(testpath, 'class_A'), exist_ok=True)\n",
        "os.makedirs(os.path.join(testpath, 'class_B'), exist_ok=True)\n",
        "os.makedirs(os.path.join(testpath, 'class_C'), exist_ok=True)\n",
        "\n",
        "from PIL import Image\n",
        "def create_dummy_image(path, color, size=(299, 299)):\n",
        "    img = Image.new('RGB', size, color=color)\n",
        "    img.save(path)\n",
        "\n",
        "# Create dummy training images (approx. 348 total to simulate previous outputs)\n",
        "for i in range(116): # 116 * 3 classes = 348\n",
        "    create_dummy_image(os.path.join(trainpath, 'class_A', f'imgA_{i:03d}.png'), (255, 100, 100))\n",
        "    create_dummy_image(os.path.join(trainpath, 'class_B', f'imgB_{i:03d}.png'), (100, 255, 100))\n",
        "    create_dummy_image(os.path.join(trainpath, 'class_C', f'imgC_{i:03d}.png'), (100, 100, 255))\n",
        "\n",
        "# Create dummy testing images (approx. 153 total to simulate previous outputs)\n",
        "for i in range(51): # 51 * 3 classes = 153\n",
        "    create_dummy_image(os.path.join(testpath, 'class_A', f'testA_{i:03d}.png'), (200, 50, 50))\n",
        "    create_dummy_image(os.path.join(testpath, 'class_B', f'testB_{i:03d}.png'), (50, 200, 50))\n",
        "    create_dummy_image(os.path.join(testpath, 'class_C', f'testC_{i:03d}.png'), (50, 50, 200))\n",
        "\n",
        "print(f\"Dummy dataset created at {trainpath} and {testpath}\")\n",
        "\n",
        "\n",
        "# --- 4. Configure ImageDataGenerator instances ---\n",
        "TARGET_SIZE = (299, 299) # VGG16 typically expects 224x224, but 299x299 is also supported.\n",
        "BATCH_SIZE = 20\n",
        "\n",
        "# Training Data Generator (with augmentation)\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,          # Normalize pixel values to [0, 1]\n",
        "    rotation_range=20,       # Randomly rotate images by up to 20 degrees\n",
        "    width_shift_range=0.1,   # Randomly shift images horizontally by up to 10%\n",
        "    height_shift_range=0.1,  # Randomly shift images vertically by up to 10%\n",
        "    shear_range=0.2,         # Apply shearing transformations\n",
        "    zoom_range=0.2,          # Randomly zoom in on images\n",
        "    horizontal_flip=True,    # Randomly flip images horizontally\n",
        "    fill_mode='nearest'      # Strategy for filling newly created pixels\n",
        ")\n",
        "\n",
        "# Test Data Generator (ONLY rescaling, no augmentation)\n",
        "# Augmentation is only for training data to prevent overfitting.\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# --- 5. Flow Images from Directories ---\n",
        "# This loads images in batches and applies the transformations.\n",
        "print(\"\\nLoading images using ImageDataGenerator...\")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    trainpath,\n",
        "    target_size=TARGET_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical' # For multi-class classification (one-hot encoded labels)\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    testpath,\n",
        "    target_size=TARGET_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False # Essential for consistent evaluation results on test set\n",
        ")\n",
        "\n",
        "# Get number of classes and class names from the generator\n",
        "num_classes = train_generator.num_classes\n",
        "class_names = list(train_generator.class_indices.keys())\n",
        "\n",
        "print(f\"Found {train_generator.samples} training images belonging to {num_classes} classes.\")\n",
        "print(f\"Found {test_generator.samples} test images belonging to {num_classes} classes.\")\n",
        "print(\"Class Names:\", class_names)\n",
        "\n",
        "\n",
        "# --- 6. Build the Model (VGG16 Feature Extractor + Custom Dense Layers) ---\n",
        "\n",
        "# Load the VGG16 model pre-trained on ImageNet.\n",
        "# `include_top=False` means we are excluding the original classification head\n",
        "# as we will add our own custom layers for our specific dataset.\n",
        "base_model = VGG16(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(TARGET_SIZE[0], TARGET_SIZE[1], 3) # Input shape for our images\n",
        ")\n",
        "\n",
        "# Freeze the layers of the base model.\n",
        "# This makes them non-trainable, preserving the learned ImageNet features.\n",
        "# Only the newly added custom layers will be trained.\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create a Sequential model and add the VGG16 base followed by custom classification layers.\n",
        "model = Sequential([\n",
        "    base_model, # The frozen VGG16 convolutional base\n",
        "    Flatten(),  # Flattens the 3D output of the base model into a 1D vector\n",
        "    Dense(256, activation='relu'), # First fully connected layer\n",
        "    Dropout(0.5), # Dropout for regularization\n",
        "    Dense(128, activation='relu'), # Second fully connected layer\n",
        "    Dropout(0.4), # Another dropout layer\n",
        "    Dense(num_classes, activation='softmax') # Output layer: one neuron per class, softmax for probabilities\n",
        "])\n",
        "\n",
        "\n",
        "# --- 7. Configure the Learning Process (model.compile()) ---\n",
        "\n",
        "# Optimizer: Adam is a good general-purpose optimizer. Using a small learning rate.\n",
        "chosen_optimizer = Adam(learning_rate=0.0001)\n",
        "\n",
        "# Loss Function: 'categorical_crossentropy' for multi-class classification with one-hot encoded labels.\n",
        "chosen_loss_function = 'categorical_crossentropy'\n",
        "\n",
        "# Metrics: What to monitor during training (e.g., accuracy).\n",
        "chosen_metrics = ['accuracy']\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=chosen_optimizer,\n",
        "    loss=chosen_loss_function,\n",
        "    metrics=chosen_metrics\n",
        ")\n",
        "\n",
        "# Print the summary of the complete model architecture\n",
        "print(\"\\n--- Complete Model Summary (VGG16 with Custom Dense Layers) ---\")\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# --- 8. Define Callbacks for Training Management ---\n",
        "# Callbacks are special functions called at various stages of the training process.\n",
        "\n",
        "# Directory to save model checkpoints\n",
        "checkpoint_dir = 'model_checkpoints'\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "checkpoint_filepath = os.path.join(checkpoint_dir, 'best_model_vgg16.h5')\n",
        "\n",
        "# 8.1 ModelCheckpoint: Save the best model encountered so far.\n",
        "# Saves if the 'val_loss' (validation loss) is the least.\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    monitor='val_loss',     # Monitor validation loss\n",
        "    save_best_only=True,    # Only save if val_loss improves\n",
        "    mode='min',             # 'min' mode for loss (we want the minimum loss)\n",
        "    verbose=1               # Show messages when saving\n",
        ")\n",
        "\n",
        "# 7.2 EarlyStopping: Stop training if validation loss doesn't improve for 'patience' epochs.\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,             # Stop if no improvement for 5 epochs\n",
        "    restore_best_weights=True, # Load weights from the best epoch before stopping\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 7.3 ReduceLROnPlateau: Reduce learning rate if validation loss plateaus.\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,             # Reduce LR by factor of 0.2\n",
        "    patience=3,             # Wait 3 epochs before reducing\n",
        "    min_lr=0.000001,        # Minimum learning rate\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 7.4 CSVLogger: Log training history to a CSV file.\n",
        "csv_logger = CSVLogger('training_log.csv', append=True)\n",
        "\n",
        "# List of all callbacks to be used during training\n",
        "callbacks_list = [\n",
        "    model_checkpoint,\n",
        "    early_stopping,\n",
        "    reduce_lr,\n",
        "    csv_logger\n",
        "]\n",
        "\n",
        "\n",
        "# --- 9. Train the Model (model.fit()) ---\n",
        "# This starts the training loop with your specified parameters and callbacks.\n",
        "print(\"\\n--- Starting Model Training ---\")\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE, # Number of batches per epoch\n",
        "    epochs=25, # Train for a maximum of 25 epochs\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=test_generator.samples // BATCH_SIZE, # Number of validation batches per epoch\n",
        "    callbacks=callbacks_list, # Apply all defined callbacks\n",
        "    verbose=1 # Show training progress\n",
        ")\n",
        "\n",
        "print(\"\\nModel training complete.\")\n",
        "print(f\"Best model (based on validation loss) saved to: {checkpoint_filepath}\")\n",
        "\n",
        "\n",
        "# --- 10. Evaluate the Model ---\n",
        "# After training, load the best saved model and evaluate its performance on the test set.\n",
        "try:\n",
        "    loaded_model = tf.keras.models.load_model(checkpoint_filepath)\n",
        "    print(f\"\\nLoaded best model from {checkpoint_filepath}\")\n",
        "    loss, accuracy = loaded_model.evaluate(test_generator, steps=test_generator.samples // BATCH_SIZE)\n",
        "    print(f\"\\nFinal Test Loss (best model): {loss:.4f}, Final Test Accuracy (best model): {accuracy:.4f}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nCould not load best model for final evaluation: {e}\")\n",
        "    print(\"Evaluating the current model state (if training was not run or save failed).\")\n",
        "    loss, accuracy = model.evaluate(test_generator, steps=test_generator.samples // BATCH_SIZE)\n",
        "    print(f\"\\nFinal Test Loss: {loss:.4f}, Final Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "\n",
        "# --- 11. Plotting Training History ---\n",
        "# Visualize the training and validation accuracy/loss over epochs.\n",
        "if 'history' in locals() and history is not None:\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Plot training & validation accuracy\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Model Accuracy over Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(loc='upper left')\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Plot training & validation loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Model Loss over Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# --- 12. Clean up dummy data and checkpoints (Optional) ---\n",
        "# Uncomment these lines if you want to remove the dummy dataset and saved models after inspection.\n",
        "if os.path.exists(trainpath):\n",
        "    shutil.rmtree(trainpath)\n",
        "if os.path.exists(testpath):\n",
        "    shutil.rmtree(testpath)\n",
        "if os.path.exists(checkpoint_dir):\n",
        "    shutil.rmtree(checkpoint_dir)\n",
        "if os.path.exists('training_log.csv'):\n",
        "    os.remove('training_log.csv')\n",
        "print(f\"\\nDummy dataset, checkpoints directory and training log file removed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zWsBQzE9Cgb5",
        "outputId": "101d75d3-eda7-4ea9-ff5d-a94d5b955239"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive mounted successfully!\n",
            "Using dummy dataset located at: \n",
            "  Train: /content/train\n",
            "  Test: /content/test\n",
            "Creating dummy dataset for demonstration...\n",
            "Dummy dataset created at /content/train and /content/test\n",
            "\n",
            "Loading images using ImageDataGenerator...\n",
            "Found 348 images belonging to 3 classes.\n",
            "Found 153 images belonging to 3 classes.\n",
            "Found 348 training images belonging to 3 classes.\n",
            "Found 153 test images belonging to 3 classes.\n",
            "Class Names: ['class_A', 'class_B', 'class_C']\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "\n",
            "--- Complete Model Summary (VGG16 with Custom Dense Layers) ---\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ vgg16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41472</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">10,617,088</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ vgg16 (\u001b[38;5;33mFunctional\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │    \u001b[38;5;34m14,714,688\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41472\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │    \u001b[38;5;34m10,617,088\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m387\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,365,059</span> (96.76 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,365,059\u001b[0m (96.76 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,650,371</span> (40.63 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,650,371\u001b[0m (40.63 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> (56.13 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m14,714,688\u001b[0m (56.13 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Starting Model Training ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22s/step - accuracy: 0.4119 - loss: 1.2705 "
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1: val_loss improved from inf to 0.75116, saving model to model_checkpoints/best_model_vgg16.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m542s\u001b[0m 32s/step - accuracy: 0.4141 - loss: 1.2645 - val_accuracy: 1.0000 - val_loss: 0.7512 - learning_rate: 1.0000e-04\n",
            "Epoch 2/25\n",
            "\u001b[1m 1/17\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:02\u001b[0m 23s/step - accuracy: 0.4500 - loss: 1.0346"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2: val_loss improved from 0.75116 to 0.74934, saving model to model_checkpoints/best_model_vgg16.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 10s/step - accuracy: 0.4500 - loss: 1.0346 - val_accuracy: 1.0000 - val_loss: 0.7493 - learning_rate: 1.0000e-04\n",
            "Epoch 3/25\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22s/step - accuracy: 0.6441 - loss: 0.7870 \n",
            "Epoch 3: val_loss improved from 0.74934 to 0.37587, saving model to model_checkpoints/best_model_vgg16.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m559s\u001b[0m 33s/step - accuracy: 0.6480 - loss: 0.7823 - val_accuracy: 1.0000 - val_loss: 0.3759 - learning_rate: 1.0000e-04\n",
            "Epoch 4/25\n",
            "\u001b[1m 1/17\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:05\u001b[0m 23s/step - accuracy: 0.8000 - loss: 0.4190"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 4: val_loss improved from 0.37587 to 0.36354, saving model to model_checkpoints/best_model_vgg16.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 10s/step - accuracy: 0.8000 - loss: 0.4190 - val_accuracy: 1.0000 - val_loss: 0.3635 - learning_rate: 1.0000e-04\n",
            "Epoch 5/25\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21s/step - accuracy: 0.8536 - loss: 0.4814 \n",
            "Epoch 5: val_loss improved from 0.36354 to 0.22004, saving model to model_checkpoints/best_model_vgg16.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m555s\u001b[0m 33s/step - accuracy: 0.8546 - loss: 0.4782 - val_accuracy: 1.0000 - val_loss: 0.2200 - learning_rate: 1.0000e-04\n",
            "Epoch 6/25\n",
            "\u001b[1m 1/17\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:08\u001b[0m 27s/step - accuracy: 0.8500 - loss: 0.3864"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 6: val_loss improved from 0.22004 to 0.21319, saving model to model_checkpoints/best_model_vgg16.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 10s/step - accuracy: 0.8500 - loss: 0.3864 - val_accuracy: 1.0000 - val_loss: 0.2132 - learning_rate: 1.0000e-04\n",
            "Epoch 7/25\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21s/step - accuracy: 0.9430 - loss: 0.3356 \n",
            "Epoch 7: val_loss improved from 0.21319 to 0.13242, saving model to model_checkpoints/best_model_vgg16.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m568s\u001b[0m 34s/step - accuracy: 0.9427 - loss: 0.3341 - val_accuracy: 1.0000 - val_loss: 0.1324 - learning_rate: 1.0000e-04\n",
            "Epoch 8/25\n",
            "\u001b[1m 1/17\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:48\u001b[0m 22s/step - accuracy: 0.9000 - loss: 0.2314"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 8: val_loss improved from 0.13242 to 0.12999, saving model to model_checkpoints/best_model_vgg16.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 11s/step - accuracy: 0.9000 - loss: 0.2314 - val_accuracy: 1.0000 - val_loss: 0.1300 - learning_rate: 1.0000e-04\n",
            "Epoch 9/25\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22s/step - accuracy: 0.9594 - loss: 0.2142 \n",
            "Epoch 9: val_loss improved from 0.12999 to 0.06798, saving model to model_checkpoints/best_model_vgg16.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m560s\u001b[0m 33s/step - accuracy: 0.9594 - loss: 0.2146 - val_accuracy: 1.0000 - val_loss: 0.0680 - learning_rate: 1.0000e-04\n",
            "Epoch 10/25\n",
            "\u001b[1m 1/17\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:36\u001b[0m 21s/step - accuracy: 0.9500 - loss: 0.1369"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 10: val_loss improved from 0.06798 to 0.06583, saving model to model_checkpoints/best_model_vgg16.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 9s/step - accuracy: 0.9500 - loss: 0.1369 - val_accuracy: 1.0000 - val_loss: 0.0658 - learning_rate: 1.0000e-04\n",
            "Epoch 11/25\n",
            "\u001b[1m 1/17\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:17\u001b[0m 24s/step - accuracy: 1.0000 - loss: 0.1904"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OZ7tPBiCDIKm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}